{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at hfl/chinese-roberta-wwm-ext were not used when initializing TermModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing TermModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TermModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of TermModel were not initialized from the model checkpoint at hfl/chinese-roberta-wwm-ext and are newly initialized: ['term_key_transform.bias', 'leftright_value_transform.bias', 'leftright_value_transform.weight', 'inner_query.bias', 'inner_query.weight', 'term_key_transform.weight', 'term_value_transform.bias', 'classifier.bias', 'term_value_transform.weight', 'leftright_key_transform.bias', 'classifier.weight', 'leftright_key_transform.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading finetuned ckpt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "# from code.get_args import get_parser\n",
    "# import get_args\n",
    "from attn.model import TermModel\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizerFast\n",
    "import torch.utils.data as td\n",
    "# import lac\n",
    "# from LAC import LAC\n",
    "\n",
    "\n",
    "\n",
    "# args = parser.parse_args(['--train_path', '../huawei_dataset/pc.txt','--valid_path','../huawei_dataset/medicine.txt'])\n",
    "\n",
    "\n",
    "    # parser.add_argument('--sample_probs_choice', type=int, default=1)\n",
    "    # parser.add_argument('--neg_ratio_choice', type=int, default=1 )\n",
    "    # parser.add_argument('--context_size', type=int,default=3)\n",
    "    # parser.add_argument('--log_dir', type=str, default=\"../logs\" )\n",
    "    # parser.add_argument('--uid', type=str, default=\"\")\n",
    "    # parser.add_argument('--early_stop_epoch', type=int, default = 10000)\n",
    "    # parser.add_argument('--use_two_classifier', type=int, default=0)\n",
    "\n",
    "sam = 0\n",
    "uniq = 'wzt_alladdc'\n",
    "epoch = 1\n",
    "\n",
    "class Args:\n",
    "    model_name = \"hfl/chinese-roberta-wwm-ext\"\n",
    "\n",
    "    # finetuned_ckpt = \"ckpts/0914_sam1neg1_contextsize2/0914_sam1neg1_contextsize2_3.pt\"\n",
    "    # context_size = 3\n",
    "\n",
    "    # wzt_alladdc_neg5sam1_epoch1_split_18\n",
    "\n",
    "    # 试试epoch4？\n",
    "    # finetuned_ckpt = f\"ckpts/{uniq}_neg5sam{sam}/{uniq}_neg5sam{sam}_epoch{epoch}_split_19.pt\"\n",
    "    finetuned_ckpt = f\"/data2/private/wzt/term11_22/term/attn/ckpts/strict_neg_5sam1/strict_neg_5sam1_epoch1_split_19.pt\"\n",
    "    # finetuned_ckpt = f\"ckpts/{uniq}_neg5sam{sam}/{uniq}_neg5sam{sam}_epoch{epoch}.pt\"\n",
    "    context_size = 3\n",
    "    \n",
    "    use_two_classifier = 0\n",
    "\n",
    "\n",
    "\n",
    "args = Args()\n",
    "\n",
    "tk = BertTokenizerFast.from_pretrained(args.model_name)\n",
    "\n",
    "\n",
    "# train_sents,train_labels = get_sents_labels(args.train_path,args.max_length)\n",
    "# valid_sents,valid_labels = get_sents_labels(args.valid_path,args.max_length)\n",
    "\n",
    "# train_pos_ngrams = get_ngrams(train_sents,train_labels,args.max_length)\n",
    "# valid_pos_ngrams = get_ngrams(valid_sents,valid_labels,args.max_length)\n",
    "\n",
    "# valid_terms = get_terms(valid_pos_ngrams)\n",
    "\n",
    "# lac = LAC(mode='seg')\n",
    "# from IPython import embed; embed(header=\"true\")quit()\n",
    "\n",
    "# train_ngrams = add_neg(train_pos_ngrams)\n",
    "# train_sents, train_idxes, train_labels = open_train_ngrams(train_ngrams)\n",
    "\n",
    "\n",
    "# valid_sents, valid_idxes, valid_labels = get_valid_ngrams(valid_sents)\n",
    "\n",
    "\n",
    "# train_dataset = SophDatasetNegSampling(train_pos_ngrams, tk,args)\n",
    "# valid_dataset = SophDatasetNegSampling(valid_pos_ngrams, tk,args)\n",
    "# train_dataloader = td.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=4,collate_fn=SophDatasetNegSampling.collate_fn)\n",
    "# valid_dataloader = td.DataLoader(valid_dataset, batch_size=args.batch_size, shuffle=False, num_workers=4,collate_fn=SophDatasetNegSampling.collate_fn)\n",
    "\n",
    "\n",
    "# from IPython import embed; embed(header=\"in soph 48\")\n",
    "# from torch.optim import AdamW\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = TermModel.from_pretrained(args.model_name, num_labels=2)\n",
    "setattr(model.config, 'args', args)\n",
    "\n",
    "initialize_from_existing_ckpt = not (args.finetuned_ckpt == \"\" or args.finetuned_ckpt is None)\n",
    "\n",
    "if initialize_from_existing_ckpt:\n",
    "    print(\"loading finetuned ckpt\")\n",
    "    model.load_state_dict(torch.load(args.finetuned_ckpt))\n",
    "setattr(model, 'tk', tk)\n",
    "# model = nn.DataParallel(model)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:00, 557227.09it/s]\n",
      "100%|██████████| 10000/10000 [00:27<00:00, 367.68it/s]\n",
      "100%|██████████| 2222012/2222012 [01:40<00:00, 22122.42it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "def my_ngram(_len, _n):\n",
    "    res = []\n",
    "    for i in range(_len):\n",
    "        for j in range(_n):\n",
    "            if i+j+1 <= _len:\n",
    "                res.append((i, i+j+1))\n",
    "    return res\n",
    "def get_prefix_len(sent,idx):\n",
    "    sum = 0\n",
    "    for i in range(idx):\n",
    "        sum+=len(sent[i])\n",
    "    return sum\n",
    "def have_chinese(strs):\n",
    "    for _char in strs:\n",
    "        if '\\u4e00' <= _char <= '\\u9fa5':\n",
    "            return True\n",
    "    return False\n",
    "N=8\n",
    "global_dict  ={}\n",
    "lines_cnt = 0\n",
    "\n",
    "path = '/home/wangzhitong/data2/strict_sents.txt'\n",
    "with open(path,'r') as f:\n",
    "    for line in tqdm(f):\n",
    "        lines_cnt+=1\n",
    "\n",
    "with open(path,'r') as f:\n",
    "    for i,line in enumerate(tqdm(f,total=lines_cnt)):\n",
    "        line = line.strip()\n",
    "        line = ''.join(line.split())\n",
    "        n_gram_idxes = my_ngram(len(line),N)\n",
    "        for idx in n_gram_idxes:\n",
    "            if idx[0]!=idx[1]-1:\n",
    "                char_idx = get_prefix_len(line,idx[0]),get_prefix_len(line,idx[1])-1\n",
    "                n_gram = ''.join(line[idx[0]:idx[1]])\n",
    "                if have_chinese(n_gram):\n",
    "                    global_dict[n_gram] = global_dict.get(n_gram,[])\n",
    "                    if global_dict[n_gram]!=[1]:\n",
    "                        global_dict[n_gram].append((line,i,char_idx))\n",
    "all_ngrams = list(global_dict.keys())\n",
    "\n",
    "with open(path,'r') as f:\n",
    "       data = f.readlines()\n",
    "infer_sents = [list(''.join(item.strip().split())) for item in data]\n",
    "from tqdm import tqdm\n",
    "global_set = list(global_dict.keys())\n",
    "encoded_glb_dict = {}\n",
    "for g in tqdm(global_set):\n",
    "    encoded = ''.join(tk.tokenize(g))\n",
    "    encoded_glb_dict[encoded] = g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_terms = []\n",
    "with open('/home/wangzhitong/data2/strict_terms.txt','r') as f:\n",
    "    # terms = f.readlines()\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        key_terms.append(line)\n",
    "key_terms = set(key_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_terms = set(['HAS-A关系', 'IS-A关系', '编程', '超类', '抽象', '抽象数据类型', '对象', '方法', '封装', '格式化运算符', '格式化字符串', '过程抽象', '继承', '继承层次结构', '接口', '可计算', '可修改性', '类', '列表', '列表解析式', '模拟',  '数据抽象', '数据结构', '数据类型', '算法', '提示符', '异常', '真值表', '子类', '字典', '字符串', '大记法', '对数', '对数线性', '蛮力法', '平方',  '清点法', '时间复杂度', '数量级', '线性', '指数', '最坏情况',  '遍历链表', '队列', '后序', '回文', '节点', '链表', '列表', '模拟', '匹配括号', '前序', '数据变量', '双端队列', '头部', '完全括号', '线性数据结构', '优先级', '栈', '中序', '递归', '递归调用', '动态规划', '分形', '栈帧', '步长', '槽', '插入排序', '冲突', '冲突处理', '短冒泡', '二分搜索', '分割点', '分区', '归并', '归并排序', '基准值', '聚集', '开放定址法', '快速排序', '链接法', '冒泡排序', '平方取中法', '平方探测', '三数取中法', '散列', '散列表', '散列函数', '顺序搜索', '完美散列函数', '希尔排序', '线性探测', '选择排序', '映射', '载荷因子', '再散列', '折叠法', 'AVL树', '边', '层数', '二叉堆', '二叉树', '二叉搜索树', '父节点', '高度', '根节点', '后继节点', '后序遍历', '节点', '路径', '前序遍历', '树', '完全二叉树', '兄弟节点', '旋转', '叶子节点', '映射', '优先级队列', '中序遍历', '子节点', '子树', '最小堆','最大堆', '边', '代价', '顶点', '环', '宽度优先搜索', '括号特性', '邻接表', '邻接矩阵', '路径', '强连通单元', '权重', '深度优先森林', '深度优先搜索', '生成树', '拓扑排序', '无环图', '无控制泛滥法', '有环图', '有向图', '有向无环图', '最短路径', 'DFA图', 'DNA串', 'KMP图', 'RSA算法', '八叉树', '层数', '抖动', '公钥加密', '均摊分析', '量化', '确定有限状态自动机', '塔', '跳表', '像素', '映射', '子串', '字典','信息隐藏'])\n",
    "out = {'DFA','DFS','BFS','KMP','DAG','FIFO','LIFO','self','独立于实现','浅相等','深相等','普通情况','基本情况','堆的有序性','相邻'}\n",
    "# key_terms = key_terms.union(out)\n",
    "key_terms = set([item for item in key_terms if item in global_dict])\n",
    "key_terms = set([item for item in key_terms if len(global_dict[item])>2])\n",
    "print(key_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation as enpunc\n",
    "from zhon.hanzi import punctuation as zhpunc\n",
    "punc = set(enpunc+zhpunc)\n",
    "for item in infer_sents:\n",
    "    # print(item)\n",
    "    if item[-1] not in punc:\n",
    "        item.append('。')\n",
    "    # print(item)\n",
    "    # break\n",
    "# infer_text = [''.join(item) for item in infer_sents]\n",
    "# infer_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "100%|██████████| 10000/10000 [04:09<00:00, 40.01it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "smt = 2\n",
    "res=[]\n",
    "for sent in tqdm(infer_sents):\n",
    "    sent = sent[:128]\n",
    "    out = model.inference_one_sent(''.join(sent), top_k = -1, verbose=False,sm=True,smt=smt)\n",
    "    res.append(out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = '轻小说是一种具有高效地将故事内容传达给读者的通俗的写作手法'\n",
    "out = model.inference_one_sent(sent, top_k = 100, verbose=False,sm=True)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exe_format(res):\n",
    "    new_res = []\n",
    "    for item in tqdm(res):\n",
    "        new_item = []\n",
    "        for jtem in item:\n",
    "            print(jtem)\n",
    "            new_item.append((''.join(jtem[0][0]),jtem[0][1].cpu().numpy().tolist(),format(jtem[2],'.4f')))\n",
    "        break\n",
    "    return new_res\n",
    "exe_format(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def found_term_by_count_threshold(prob_thres=0, thres=0):\n",
    "    potential_ngram_count = {}\n",
    "    for i,sent_ngram in enumerate(tqdm(res)):\n",
    "        for each_ngram in sent_ngram:\n",
    "            _word, prob = each_ngram\n",
    "            _word = ''.join(_word)\n",
    "            if _word in encoded_glb_dict:\n",
    "                word = encoded_glb_dict[_word]\n",
    "                # if word=='' or word=='信息隐藏':\n",
    "                #     print(word,''.join(infer_sents[i][:256]))\n",
    "                #     print(prob)\n",
    "                if prob>prob_thres:\n",
    "                    # add_score = prob\n",
    "                    add_score = 1\n",
    "                    # if prob>1:\n",
    "                    \n",
    "                    # # elif prob>1:\n",
    "                    #     add_score = 2\n",
    "                    # elif prob > 0.5:\n",
    "                    #     add_score = 1\n",
    "                    # else:\n",
    "                    #     add_score = 0.5\n",
    "\n",
    "                    if word not in potential_ngram_count:\n",
    "                        potential_ngram_count[word] = add_score#prob\n",
    "                    else:\n",
    "                        potential_ngram_count[word] += add_score#prob\n",
    "                \n",
    "    extracted_terms = []\n",
    "    for key in potential_ngram_count:\n",
    "        if potential_ngram_count[key] >= min(thres, len(global_dict[key][0])):\n",
    "            extracted_terms.append(key)\n",
    "    print(len(extracted_terms))\n",
    "    extracted_terms = set(extracted_terms)\n",
    "    intersect = extracted_terms.intersection(key_terms)\n",
    "    diff_rec = key_terms.difference(extracted_terms)\n",
    "    diff_prec = extracted_terms.difference(key_terms)\n",
    "    int_len = len(intersect)\n",
    "    ext_len = len(extracted_terms)\n",
    "\n",
    "    print(int_len)\n",
    "    print(len(key_terms))\n",
    "    print('p:',int_len/ext_len)\n",
    "    print('r:',int_len/len(key_terms))\n",
    "    print(diff_rec)\n",
    "    print(diff_prec)\n",
    "    return extracted_terms\n",
    "    \n",
    "\n",
    "extracted_terms =  found_term_by_count_threshold(0, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = set(str(i) for i in range(10))\n",
    "num\n",
    "num_extracted = []\n",
    "new_extracted = []\n",
    "for item in extracted_terms:\n",
    "    # if set(item).intersection(num):\n",
    "    if '图' in item or '代码清单' in item or '表' in item:\n",
    "        num_extracted.append(item)\n",
    "    else:\n",
    "        new_extracted.append(item)\n",
    "intersect =set(new_extracted).intersection(key_terms)\n",
    "int_len = len(intersect)\n",
    "ext_len = len(new_extracted)\n",
    "print('p:',int_len/ext_len)\n",
    "print('r:',int_len/len(key_terms))\n",
    "diff_prec = set(new_extracted).difference(key_terms)\n",
    "print(diff_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:10<00:00, 931.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8418\n",
      "7522\n",
      "1661229\n",
      "p: 0.8935614160133049\n",
      "r: 0.004527972964594285\n",
      "p: 0.8937737642585551\n",
      "r: 0.004527972964594285\n"
     ]
    }
   ],
   "source": [
    "seet = {}\n",
    "# seet = {'浅相等','深相等'}\n",
    "# seet = {'日常生活','这一过程'}\n",
    "# seet = {'可修改性', '信息隐藏', '堆的有序性', 'HAS-A关系', '相邻', '记法', '最短路径', '前序'}\n",
    "# seet = {'相邻', '代价'}\n",
    "# seet= {'前序', '最短路径', '信息隐藏'}\n",
    "# seet = {'着力点'}\n",
    "# seet = {'reddit', '浓硫酸', '豨科', '徐惠滋', '李秀英', '构型保持', '边防检查总站', '蓟', '萨仁高娃', '王文惠', '台中市政府', '吉剌思巴监藏巴藏卜', '天津经济技术开发区'}\n",
    "# seet = {'支气管', '唐宁', '楼文英', '深化党和国家机构改革', '丝织物', '洛追坚赞', '王延康', '冯玉忠', '库尔班江·买买提', '杨澄宇', '中华人民共和国公安部',  '杨仁争', '国家综合配套改革试验区'}\n",
    "# seet = {'浓硫酸','边防检查总站','台中市政府','地理学界','合同','声波','支气管'}\n",
    "seet ={'浓硫酸','浓硝酸','稀硫酸','稀硝酸','高氯酸','浓磷酸','稀磷酸','浓盐酸','稀盐酸','稀醋酸','浓醋酸','浓溶液','浓咖啡','稀奶油'}\n",
    "# seet = {'红玫瑰','白玫瑰'}\n",
    "seel = []\n",
    "print_term_dict = {}\n",
    "occur_words = []\n",
    "saveres = []\n",
    "def see_term_by_count_threshold(prob_thres=0, thres=0,mean_thres=0):\n",
    "    \n",
    "    potential_ngram_count = {}\n",
    "    for i,sent_ngram in enumerate(tqdm(res)):\n",
    "        for each_ngram in sent_ngram:\n",
    "            (_word,_),prob = each_ngram\n",
    "            _word = ''.join(_word)\n",
    "            if _word in encoded_glb_dict:\n",
    "                word = encoded_glb_dict[_word]\n",
    "                occur_words.append(word)\n",
    "                # sent = ''.join(infer_sents[i][:256])\n",
    "                # if word in print_term_dict:\n",
    "                #     print_term_dict[word].append([i,prob])\n",
    "                # else:\n",
    "                #     print_term_dict[word] = [[i,prob]]\n",
    "                saveres.append([word,i,prob])\n",
    "                if word in seet:\n",
    "                    seel.append([word,''.join(infer_sents[i][:256]),prob])\n",
    "                    # print(word,''.join(infer_sents[i][:256]))\n",
    "                    # print(prob)\n",
    "                add_score = 0\n",
    "                if prob>prob_thres:\n",
    "                    add_score = 1\n",
    "\n",
    "                if word not in potential_ngram_count:\n",
    "                    potential_ngram_count[word] = [add_score,1,prob]#prob\n",
    "                else:\n",
    "                    potential_ngram_count[word][0] += add_score#prob\n",
    "                    potential_ngram_count[word][1] +=1\n",
    "                    potential_ngram_count[word][2] +=prob        \n",
    "\n",
    "    extracted_terms = []\n",
    "    for key in potential_ngram_count:\n",
    "        # if potential_ngram_count[key][0] >= min(thres, len(global_dict[key])):\n",
    "        if potential_ngram_count[key][0] >= thres:\n",
    "            # if potential_ngram_count[key][2]/potential_ngram_count[key][1] >= mean_thres:\n",
    "                extracted_terms.append(key)\n",
    "    print(len(extracted_terms))\n",
    "    extracted_terms = set(extracted_terms)\n",
    "    intersect = extracted_terms.intersection(key_terms)\n",
    "    diff_rec = key_terms.difference(extracted_terms)\n",
    "    diff_prec = extracted_terms.difference(key_terms)\n",
    "    int_len = len(intersect)\n",
    "    ext_len = len(extracted_terms)\n",
    "\n",
    "    print(int_len)\n",
    "    print(len(key_terms))\n",
    "    print('p:',int_len/ext_len)\n",
    "    print('r:',int_len/len(key_terms))\n",
    "    # print(diff_prec)\n",
    "    return extracted_terms,potential_ngram_count,diff_prec\n",
    "    \n",
    "\n",
    "extracted_terms,count_dic,diff_prec =  see_term_by_count_threshold(0.5, 2)\n",
    "num_extracted = []\n",
    "new_extracted = []\n",
    "import re \n",
    "for item in extracted_terms:\n",
    "    # if set(item).intersection(num):\n",
    "    # 图 表 代码清单\n",
    "    if re.search(r'图\\d+\\-\\d+',item) or re.search(r'表\\d+\\-\\d+',item) or re.search(r'代码清单\\d+\\-\\d+',item) or re.search(r'\\d+\\.\\d+(\\.\\d)?',item):\n",
    "    # if '图' in item or '代码清单' in item or '表' in item:\n",
    "        num_extracted.append(item)\n",
    "    else:\n",
    "        new_extracted.append(item)\n",
    "print('p:',len(key_terms.intersection(new_extracted))/len(new_extracted))\n",
    "print('r:',len(key_terms.intersection(new_extracted))/len(key_terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 346116/2395389 [00:00<00:01, 1577415.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "其他 主要文章：核合成和恒星核合成虽然它是在大霹雳中合成的，但是锂（和铍及硼）在宇宙中的含量明显低于其他元素。 0.006042726\n",
      "其他 泪水冲走了其他动物和雀鸟；一时间，爱丽丝已被一群动物包围。 0.0075329747\n",
      "其他 在与摩城签约后的一年半，组合于1967年转至摩城旗下的灵魂唱片（soulrecords），并录制了〈〉以及其他随之而来的热门歌曲，包括〈〉、〈friendshiptrain〉、〈〉和〈〉。 0.007156176\n",
      "其他 从6月30日起瓦德和其他被捕者开始绝食，他们于7月4日被释放，8月30日其他的所有控告也全部被放弃。 0.0064896774\n",
      "其他 从6月30日起瓦德和其他被捕者开始绝食，他们于7月4日被释放，8月30日其他的所有控告也全部被放弃。 0.004020675\n",
      "其他 在尾巴底部的两侧各有一块白色的毛，与狒狒和其他猴子的屁股非常相像 0.012619244\n",
      "其他 阿根廷同时与南美其他国相比拥有较良好的工业基础，自然资源也非常丰富，阿根廷受益于丰富的自然资源，高度受教育的人口，出口导向的农业部门，多样的工业基础。 0.007055091\n",
      "其他 里贝克的律师声称麦当劳的咖啡送到消费者手中的时候是华氏180-190度（摄氏82-88度），其他餐厅的咖啡一般在华氏135-140度（摄氏57-60度），麦当劳的咖啡更热，容易造成烫伤，是产品缺陷。 0.007788985\n",
      "其他 在慈运理的领导下，信仰新教的苏黎世州与市同其他新教州组成抵抗联盟“基督教公民联盟”，其中还包括康斯坦茨和斯特拉斯堡。 0.0032671294\n",
      "其他 黎巴嫩不同于其他中东国家以穆斯林为主，黎巴嫩宗教分布比较类似于波赫和阿尔巴尼亚，都为穆斯林和基督徒各占一半的比例。 0.005233209\n",
      "其他 与其他非洲国家一致，足球是科特迪瓦的第一运动。 0.0027269053\n",
      "其他 虽然他和诺勒斯与其他指挥官同样有责任，但他将罪过推给诺勒斯来回避罪责。 0.0025935709\n",
      "其他 他们一入宇宙，就着手依埃努的大乐章旋律建造世界，维拉时代开始，但米尔寇向其他维拉宣布他的主权，并和他的追随者对阿尔达大加破坏，扰乱已成形的部分，并转作私有用途。 0.010880384\n",
      "其他 庞培则在色萨利与其他贵族共和派成员汇合，在后者的再三催促下，庞培军在法萨卢斯附近与凯撒军正面冲突。 0.0024777327\n",
      "其他 同时其他角色们也有不同于原本角色设定的意外演出，让人惊呼连连。 0.005182006\n",
      "其他 其中碇真嗣的两位同学（铃原冬二和相田剑介）的名字取自于村上龙的小说，其他人物的名字或姓氏也都来自漫画或日本帝国海军舰只的名称。 0.005372606\n",
      "其他 ucsc成立于2013年，团队已经在柬埔寨与其他机构参加了许多足球赛和田径比赛。 0.0054696663\n",
      "其他 其他较低地区接收的雨水更少，路德维尔福站(coordinates:s32°14’27.9”e20°05’44.5”)年降雨为180mm。 0.0065951496\n",
      "其他 tv版第7作由日本华纳音乐，但主题歌方面与第6作一样启用了其他公司的艺术家。 0.006905309\n",
      "其他 如果不能彻底击败拥有比克罗塔更强大的“剑之逻辑”和“王座世界”的奥瑞克斯，所有人类，甚至入侵太阳系的其他外星种族，都将面临被黑暗奴役的命运。 0.011766217\n",
      "其他 当基利在1991/92球季首次上阵后，他除了1998/99球季之外，其他赛季都或多或少代表过列斯联上阵。 0.0077155246\n",
      "其他 在布莱德求学时，学校老师都以为布莱德非自主的发出怪声和颈部抽动是想要引起别人的注意或是调皮捣蛋，因此常被老师处罚及遭受其他孩子的愚弄和嘲笑，连他的父亲也觉得丢脸，大声怒吼叫他停止。 0.015513978\n",
      "其他 电战机的功能也被用在其他机种如：反潜机、运输机、轰炸机、直升机、侦察机上，美国也特别创立专职类别的电战机，如：海军的ea-6、空军的ef-111a等。 0.0057670726\n",
      "其他 此外，藏传佛教的其他教派也在这段时期陆陆续续地形成，如白教（噶举派）、花教（萨迦派）、红教（宁玛派）等。 0.0050904206\n",
      "其他 后赴德国深造，其他艺术家专注于改变整体环境，在德国卡塞尔大学攻读的周春芽，则浸淫于印象派、立体主义以及表现主义当中，在学习的过程中他找到了自己在新表现主义中独树一格的特性。 0.0028726659\n",
      "其他 波兰饮食和其他斯拉夫国家的饮食文化有很多相似之处，特别是捷克、斯洛伐克、白俄罗斯、乌克兰和俄罗斯。 0.0027130893\n",
      "其他 当时原元朗北郊区议员文炳南选择于本区争取连任，由于未有其他对手，文炳南自动当选。 0.0035441148\n",
      "其他 而在现代法律，起源于衡平法的强制履行合同和禁制令也适用于劳动法、行政法等其他领域。 0.003481442\n",
      "其他 焕基美术馆常设展览厅中展示了许多金焕基的作品，别馆的企划展览厅展示了其他年轻画家的作品，每年约举办2至3次的大小画作展。 0.005215755\n",
      "其他 此外，也有其他层级的政府已经建立了opendata的网站，如渥太华和加州。 0.006617066\n",
      "其他 参差重频是仅有的几个相似技术之一，其中还包括抖动脉冲重复频率（脉冲时间是变化且不规则的），脉冲频率调制，以及其他几个类似为了降低无意识的信号同步的策略。 0.007206331\n",
      "其他 板桥地检署王正皓检察官指挥法务部调查局台北县调查站侦办树林农会涉及不法贷款或放款弊案，业经侦查终结，共起诉22人，包括树林市农会信用部主任郑淑贞、圳安分部主任郑玉麟、放款专员郑骥、猐寮分部（现改名金寮分部）前主任刘丽珠及其他专员、员工等13人，及办理不动产买卖业者蓝国珍等9人。 0.0043599573\n",
      "其他 其他三种合金是近代才开始的研究，由于其金属的活性，需要利用电解方式才能提炼纯金属。 0.011783395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 654160/2395389 [00:00<00:01, 1390949.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "其他 运河事件后，英国决定将其全球军事部署退防至苏伊士运河以西，放弃在全球其他地区单方面出兵干涉的能力。 0.0039550955\n",
      "其他 一般在游戏开始前，玩家必须先构筑自己的牌组好参加游戏：在任何时候，每张牌只能位于下列其中一个“区域”，其中战场和堆叠为共用区域，其他区域则是每位玩家各自独立。 0.011551445\n",
      "其他 大禹治水的过程记载在《尚书·禹贡》，当时的已知世界被划分为九州，洛阳属禹贡九州的豫州，居其他八州之中央。 0.016279407\n",
      "其他 檀是相当古老的中文词汇，《诗经》魏风有《伐檀》三章：估计成书于东周或更早的《诗经》，一般认为收录的是中国3000年左右以前的黄河中、下游的民歌，当时中国此一区域的檀树，就只有青檀一种，其他分布在南方的黄檀等，其所在区域可能尚非中国版图，所以一般推断此处用以制辐、制轮的檀，就是青檀。 0.009133799\n",
      "其他 《综艺》认为影片在很多层面上都具有开创性，尤其是它在主角性取向之外与其他青春片的惊人相似。 0.0038521895\n",
      "其他 在其他方向上，如果我们有对\"ax=b的另一个解z，则\"a\"(z−y)=\"az−\"ay=b−b=0。 0.011731647\n",
      "其他 除格林中心以外，洪堡大学还有众多专业图书馆以及自然科学图书馆，在格林中心启用之后，其他图书馆原址未动。 0.0032483942\n",
      "其他 其他目的地还包括尼泊尔、摩洛哥、斐济、厄瓜多尔和萨尔瓦多。 0.002380249\n",
      "其他 一些成员认为他患上神经衰弱或脑动脉硬化，然而其他成员相信他感染梅毒。 0.002850048\n",
      "其他 除了触觉敏感外，它们的其他感官没有发育。 0.00983266\n",
      "其他 他还以拨款和其他方式支持一家德国文化中心。 0.0070168106\n",
      "其他 尼尔森一直拥有《公告牌》杂志到2009年，在那年，《公告牌》与其他7本出版物被出售给易伍全球传媒控股公司。 0.005157773\n",
      "其他 其相对分子质量小，相对其他净气物质效率更高，1克的无水氢氧化锂可以吸收450cm的二氧化碳气体。 0.006037112\n",
      "其他 在这个人口不到9万的小城，就有800家生产丝绸和其他高级纺织品的公司，业务涉及生产、印花、染色、设计和销售。 0.007161432\n",
      "其他 这些学校因为有华社的大力支持，使得教育质量比其他源流学校来的高，也因此吸引了许多非华裔华小生就读。 0.010835679\n",
      "其他 key也曾与许多来自其他地方的职业人士进行合作，例如隶属于ram的便曾多次以外包艺术家的身份协助key制作游戏，而插画家驹都英二也曾经担任过《星之梦》的原画与机械设定部分，另一位插画家fumio则是曾经担任过《智代after～it'sawonderfullife～》的原画家。 0.0041879355\n",
      "其他 新兴工业化国家通常还有一些其他的共同特点，但不一定全部相同，这些包括：新兴工业化国家经常从世界贸易组织之类的国际组织和其他的内部实体得到支持。 0.013913293\n",
      "其他 新兴工业化国家通常还有一些其他的共同特点，但不一定全部相同，这些包括：新兴工业化国家经常从世界贸易组织之类的国际组织和其他的内部实体得到支持。 0.011403779\n",
      "其他 这是因为，像是其他的女童军一样，你必在任何时刻准备好去面对困难，甚至在面对危险时，你可以知道要做什么和如何去做。 0.033926643\n",
      "其他 然而，联合公报的内文并未得到彻底落实，而情势也继续恶化，尤其是在吴廷琰的胞弟、政治顾问吴廷瑈在8月21日派遣查抄舍利寺之后，华府对该次行动展开抨击，并切断了这支被吴家公器私用的特种部队所接受的美援，其他由美方供予南越的政治、经济支援项目同样遭到逐步削减。 0.0026166134\n",
      "其他 它亦有清音和咽喉音对立，与其他亚非语言一样。 0.014685083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 794034/2395389 [00:00<00:01, 1243915.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "其他 与其他图表一样，这种图表可以帮助视觉化发生了什么事情，从而更易去理解中间的工序。 0.035455637\n",
      "其他 第一发射击未击毙iassa而击中了陪同前去检查飞机的副手的大腿，他后来也爬回到其他武装人员那里。 0.0028345652\n",
      "其他 格鲁吉亚在其他方面也有高排名︰登财财产第1位、处理施工许可证第4位、创业第7位、获取信贷第8位。 0.0042916485\n",
      "其他 大火造成的325名遇难者中，有288名中小学生，其他为教师、工作人员、家长、官员等。 0.0020688216\n",
      "其他 22日，《中国季刊》的主编提姆·普林格尔（timpringle）在推特发文表示，出版社“打算立即恢复之前从中国的网站上撤下的文章”，又表示该决定是在遭遇“全球学术界和其他领域无可非议的强烈反应之后”做出的。 0.008069324\n",
      "其他 在其他场合（如线上游戏、论坛、即时通、查询系统等）登出后可以再次以相同或不同用户身份登入；在有些场合可以透过匿名身份继续使用。 0.005678822\n",
      "其他 其他甲龙科也有同样的特征，如重装甲的身驱及巨型的尾巴棒槌，但甲龙却是这个科内最大型的物种。 0.00967377\n",
      "其他 已知最早的澳洲野犬颅骨在发现约有5500年的历史，在东南亚其他区域有发现澳洲野犬的化石自5000到2500年之久，而澳洲最早的纪录是在3500年前。 0.004820801\n",
      "其他 从建筑学视角来看，它们是米诺斯宫殿的继承，同时也是青铜时代中期希腊大陆上其他民居建筑的传承。 0.0049008736\n",
      "其他 自辽世宗耶律阮以后，除了辽穆宗耶律璟是辽太宗耶律德光之子外，其他所有大辽皇帝（包括北辽的皇帝）都是耶律倍的嫡系子孙，后来蒙古帝国的契丹族著名宰相耶律楚材也是耶律倍的八世孙。 0.0044591837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 1034558/2395389 [00:00<00:01, 1091504.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "其他 除了澳大利亚、马来西亚之外，中国大陆也阻止其他国家与台湾洽谈fta，包括印尼、印度、菲律宾、以色列。 0.0026406378\n",
      "其他 亨利·基辛格认为中国与美国相同，皆认为自身在世界上占据特殊位置，但是美国具有普世主义的信念，希望将自己的价值观推广到全世界；中国较为被动，希望其他国家主动来学习中国。 0.005119016\n",
      "其他 大部分民众并没有正统的宗教信仰，但是亦有相当一部分人是佛教和基督教的信徒，在每年的耶诞节以及一些其他的纪念节日中，一些基督教信徒亦会进行一些集会来进行他们的信仰活动。 0.011140925\n",
      "其他 但相当二级机关之独立机关，其合议制成员中属专任者，应先经立法院同意后任命之；其他独立机关合议制由成员行政院长任命之。 0.006284713\n",
      "其他 此外与校内的其他商学院学生一样，同享大学所提供的“学生服务”与“学生支援”方面的延时服务。 0.0039813286\n",
      "其他 大正九年（1920年）7月，原嘉义厅辖区改为嘉义街与其他六郡后，当地部分人士因嘉义失去行政中心地位而有了置州运动，希望将州厅设置在嘉义，之后改为要求地方实质建设来促进市街发展。 0.005946346\n",
      "其他 缩写变量~user指向用户的家目录(允许用户从文件系统中的任意位置浏览它或者在其他的unix命令中使用。 0.012001888\n",
      "其他 ＊上述目的地国际机场为邻近该国首都或该国最主要枢纽机场，若要前往该国其他国际机场或国内线机场详见。 0.0056014163\n",
      "其他 据这份报告的作者zamacoursen-neff女士表示：“由于美国联邦法律中存在着危险的双重标准，与美国其他产业工作的儿童相比，在农业部门务工的儿童工作的时间过长、年龄也过轻，其工作条件也过于艰苦。” 0.0073834113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 1248444/2395389 [00:01<00:01, 973081.08it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "其他 后来比她大3岁的哥哥以及其他周边的人都建议她去练习柔道，于是她进入男衾柔道俱乐部，在进入俱乐部后，她觉得部内的年纪比她大的女成员大多都很可怕，于是在那里只呆了一天之后就决定放弃。 0.0074260747\n",
      "其他 在老的水管的内表面和其他硬水蒸发的表面也可以发现类似的沉积物。 0.01716459\n",
      "其他 礼仪是独立于其他东方礼礼仪。 0.004028619\n",
      "其他 然而在接下来几年又发生了其他的歉收，造成了总死亡数的上升。 0.015651083\n",
      "其他 德鲁隆将军的部队久攻不下之后留给内伊的只有为数不多的预备队，其他步兵要么在乌古孟胶着，要么调往右翼防守普军。 0.00372301\n",
      "其他 除了原著小说外，《贝尔戈维亚丑闻》还向其他的作品致敬。 0.008501274\n",
      "其他 其他的重要官员有纠仪长（sergeant-at-arms），为参议院的执法首长，维持参议院议场的秩序与安全；以及美国国会警察，主要在纠仪长的监督下处理例行警务工作。 0.006761894\n",
      "其他 伯内特之所以能够吸引来一些当时最好的音乐家，是因为他有着不同其他乐队队长的政策——他给自己乐手的报酬很多，并且很及时，甚至包括了解雇保险和社会保险金的支付。 0.012323257\n",
      "其他 2018年12月3日公布制作相关事宜，并宣布由制作人及编剧的钦点，直接指定由户田惠梨香担纲女主角，2019年2月21日公布其他演员人选，4月2日于滋贺县甲贺市及长滨市正式开镜。 0.0065553985\n",
      "其他 俞白眉接受记者采访时表示，电影版《分手大师》故事和原版话剧有相当大的改动，只会保留了话剧中的角色名，“电影就是藉了‘分手大师’这个名字及两个角色，其他都没什么关系，与话剧版只有5%～10%的相似”。 0.018602876\n",
      "其他 黄尾刺嘴莺、鹡鸰扇尾鹟、白脸刺莺及黑头矿鸟等其他鸟类也有可能在同一树上筑巢。 0.0054385937\n",
      "其他 其他知名作品如电影《大冒险家：森林王子》（1994年）、《兵人》（1998年）、《星际宝贝》（2002年）和《卧虎藏龙：青冥宝剑》（2016年）。 0.00568502\n",
      "其他 另外，因扩展b区在整理上有缺陷，收录了以下5个本来应该与其他汉字统一的字：而在wg2n1155文件中，亦列出了152对可考虑统一的汉字。 0.015180905\n",
      "其他 在“bad”正式发行前，杰克逊曾为这张专辑的制作写了60首歌，但在琼斯说服杰克逊裁剪了很多歌曲，“thewayyoumakemefeel”，以及其他十首歌曲最终被选定为这张专辑的曲目。 0.012718996\n",
      "其他 影音俱乐部的作家a·a·道德给了该片“a-”的评价，并称它为“仁慈甚至是充满希望地承担这个[与艺术家的关系]主题”，“在其简单的技术、永恒的精致，《霓裳魅影》实际上是对经典美学价值的一封情书—戏院、裁缝或其他的事物。” 0.012988848\n",
      "其他 于2005年5月21日起派在米登霍尔空军基地，是一个负责行政、作战支援的地面单位，并管辖其他驻英美军机场的基地单位：是美国欧洲特战司令部中的空军特战单位。 0.007083974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 1463261/2395389 [00:01<00:00, 942838.74it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "其他 制作人允许她的要求并让其他组员调整工作岗位，众人期待着卯月的归来，而凛和未央给卯月的鼓励让卯月最终召回勇气，而从自己的角色曲找回了自己的笑容。 0.008066476\n",
      "其他 史丹利和安妮经常在周末相聚，一般在半夜1:00-3:00左右分手，史丹利经常为安妮和艾丽莎·库帕垫付房租，并且叮嘱多诺万，如果安妮和其他男人相好就把她赶出去。 0.008519911\n",
      "其他 借由复杂的神经纤维和其他细胞组织连结这两个神经系统，人类才能够因应外界的环境变化而产生适当的身体反应，并且有思考、记忆、情绪变化的能力。 0.0057388456\n",
      "其他 该型车不同一般的设计：驱动电机安装在车厢底部，通过万向节驱动转向架上的变速箱，变压器装在车轴弹簧之上，因此车厢空间相对其他同时代机车较大。 0.00373703\n",
      "其他 这些公司招来了中国和其他地方的苦力。 0.0062634023\n",
      "其他 此次拆除长度约30米，石板路以青斗石及花岗石为铺设而成，另有30片公共艺术文化铸铁雕板被刨除，其中5片刻有李梅树画作(含《清溪浣衣》、《三峡后街》等)，其他雕版亦呈现老街与邻近鸢山的历史。 0.009685019\n",
      "其他 类似的装置在工业上可用于注射油脂或其他液体。 0.008250327\n",
      "其他 其他的ar-15制造商以其他的代号制造ar-15的翻版，但通俗说法中它们仍有时候被叫做“ar-15”。 0.012966334\n",
      "其他 其他的ar-15制造商以其他的代号制造ar-15的翻版，但通俗说法中它们仍有时候被叫做“ar-15”。 0.009372899\n",
      "其他 白虎星担任的白虎煞于任何时候地点都为害新娘，比只在特定时间地点才能为害新娘的七煞中的其他六煞更为凶险，稍有疏忽白虎煞就可乘虚而入害人。 0.016210854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 1650281/2395389 [00:01<00:00, 882078.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "其他 然而1980年代国际滑冰总会通过“均衡节目”的方案，在1982年实施于双人滑项目，并在1984年扩及单人滑项目，以反击流行趋势：当时选手们在节目中着重更纯粹的运动元素如跳跃，而牺牲展示滑冰技术的旋转与其他动作。 0.0064175157\n",
      "其他 华丽琴鸟在年中其他时候不经常歌唱，但多雨多雾天在其栖地散步，有时会看见它们活跃。 0.010791538\n",
      "其他 《有效条约汇编》（英语：treatiesinforce，缩写：tif），全称《有效条约汇编：美国条约及其他国际协定汇编》（英语：treatiesinforce:alistoftreatiesandotherinternationalagreementsoftheunitedstatesinforce），是由美国国务院每年出版的刊物，收录出版当年1月1日以前美国与世界各国曾经签订并于美国国务院记录在案的有效条约及国际协定。 0.0028097646\n",
      "其他 作品里发表了一套机器人伦理法则（见“机器人学三大法则”）和智能电脑，大大影响其他作家和思想家处理此一议题时的看法。 0.006113917\n",
      "其他 最后一个要求，也是非技术性要求，却决定着设计方案的成败：帝国航空部（rlm）要求这种飞机只能装备其他设计方案中不太使用的“不重要”的低功率发动机，以便这种飞机不会对列为生产主力的战斗机与轰炸机产生排挤作用。 0.00366197\n",
      "其他 国民政府时期的嫩江省相对东北其他省区而言，交通相对便利。 0.0073283785\n",
      "其他 一些五星级饭店提供雏妓服务：雏妓列在娱乐单中的“其他”标题下面。” 0.1605919\n",
      "其他 曾有过将古典乐声线分类法引入其他演唱流派，但这种分类法随着歌手们采取不借助麦克风，用他们的共鸣扩大他或她的声音的方式发声而具有争议。 0.0077283937\n",
      "其他 其他有待发展的地区包括火车和汽车总站附近地区、旧城附近过去的工业区、柏沙卡区、新城以及ružinov。 0.0061922744\n",
      "其他 用作生产金属钽的原料，也用于生产光学玻璃、电子仪器和其他钽化合物。 0.015468468\n",
      "其他 因为敌人未得到刘的其他材料，故刘只在监狱住了十天左右即获释放。” 0.009449679\n",
      "其他 对比台湾、澳门等其他地区，香港幼儿教育显得停滞不前。 0.004720654\n",
      "其他 除此之外，可能不提供其他的设施，例如洗漱用品、电视或者电话等，被褥一般是一客一换，房间也不会每天整理，需要向旅舍提出。 0.006418888\n",
      "其他 美国的法律定义电子签名是“一个与契约或其他记录在逻辑意义上相关或连接的一个记录了一个人接受其内容的电子音像、符号或程序”根据《中华人民共和国电子签名法》第二条之规定：“本法所称电子签名，是指数据电文中以电子形式所含、所附用于识别签名人身份并表明签名人认可其中内容的数据。” 0.012025783\n",
      "其他 ovf内的影像是利用棱镜或其他光学原理自主镜头中的进光折射成相，相比之下一般消费型数码相机的观景窗大都采用数位显示或复眼成像原理来运作。 0.004601089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 1826079/2395389 [00:01<00:00, 849524.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "其他 其他在大曼彻斯特区的足球会包括：约从1993年开始，酿酒厂对酒吧，会所，俱乐部的投资，加上本地组织对活动的支持，使曼彻斯特的晚间经济增长明显。 0.007458147\n",
      "其他 b-52c只有35架，除了采用较大的翼下副油箱以外，其他外观与b-52b相同。 0.0070951283\n",
      "其他 今日的南奥塞提亚连同格鲁吉亚其他地方，于1801年被沙俄吞并。 0.0018461855\n",
      "其他 碳钢（carbonsteel）是一类含碳量高于0.02%低于2%（高于2%的被称为铸铁，低于0.02%被称熟铁），而极少其他元素的钢材，也是产量最高的金属材料，相对有较高其他成分(不包括杂质)的钢称合金钢。 0.009968445\n",
      "其他 碳钢（carbonsteel）是一类含碳量高于0.02%低于2%（高于2%的被称为铸铁，低于0.02%被称熟铁），而极少其他元素的钢材，也是产量最高的金属材料，相对有较高其他成分(不包括杂质)的钢称合金钢。 0.008173788\n",
      "其他 在经过修改的步枪弹药上混用火药类型和弹药批号的做法为普遍其他国家的兵工厂所极力避免的事，因为这种粗劣手法通常会导致子弹初速不同和子弹与目标过度分散。 0.004090994\n",
      "其他 其他主要成员有梁爱兰、陈建华、朱超英等。 0.0022435149\n",
      "其他 其他特点如人物角色是有一定血量，在受到子弹、刀、爆炸、从高处摔落等都会耗损。 0.008296076\n",
      "其他 无人跟注的边池（仅有一位玩家下注，剩下其他玩家都盖牌）将会直接赢得该边池，形同退还下注于该边池之筹码。 0.0060762777\n",
      "其他 但是，这个运动没能和文艺复兴、工业革命、启蒙运动等其他欧洲国家的先进思想一样，在身为发源地的西班牙传播开来，这使得西班牙在知识思维层面开始有下滑的迹象，而西欧国家的英法则后来居上。 0.0034051244\n",
      "其他 自20世纪90年代末期以来，一个基于数据块排序算法的文件压缩工具bzip2作为gzip的替代者逐渐得到流行，它可以生成相当小的压缩文件，尤其是对于源代码和其他结构化文本更是这样，但代价是最高达4倍的内存与处理器时间消耗。 0.004947383\n",
      "其他 当记者继续追问王喜有没有其他英雄故事可以跟大家分享时，王喜断然拒绝：“由于在我离职时曾签署过一些文件，往后，我是不能向外公开任何曾经处理过的警务事宜。 0.014255014\n",
      "其他 凹嘴鹳主要吃鱼类、青蛙及蟹，也会吃雏鸟及其他陆地上的脊椎动物。 0.0025180688\n",
      "其他 相反，此属也被认为是单型的，只有棕颈犀鸟一个物种，而其他的都包含在拟皱盔犀鸟属中。 0.0072237854\n",
      "其他 往生者竖灵时也有布置灵堂、灵桌、牌位和香炉，但没有招魂幡，也不烧纸钱，其他传统的民间习俗则改以追思、祈祷、诵经或献弥撒的方式进行。 0.005671319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 2081917/2395389 [00:02<00:00, 841354.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "其他 和低温下呈反铁磁性和/或铁磁性的其他稀土金属不同，镱在1.0k以上具有顺磁性。 0.0077377963\n",
      "其他 其他的得分等级分为半胜（waza-ari）、有效（yuko）。 0.0060400493\n",
      "其他 久华洋行专事收购铜板及其他铜器，为了使铜更快更多地流入日本，日军还发放收购铜货证，持该凭证者均有权收购铜板、铜器等，然后转卖给日本的洋行。 0.009406545\n",
      "其他 1943年，《我们妇女》在雅加达首次上演，同年这套剧目还在雅加达和爪哇岛其他地方上演过很多次。 0.0010801496\n",
      "其他 这些管理器通常还提供一个窗口，显示最近的操作记录，允许用户选择更早的副本，然后编辑它们、更改它们的格式、搜索它们，以及其他高级功能。 0.011225598\n",
      "其他 素有超马女王称号的她，平时除了在芦洲慢跑社团之外，也会把自己的超马心得分享给其他跑者，期望他们能够健康跑旅，当然也有很多超马跑者跟她请益！ 0.008308389\n",
      "其他 一般情况下，供给定律描述的是：假设其他因素不变，当一件物品的相对价格上升时，其供给量会上升，反之亦然。 0.008847109\n",
      "其他 8岁时，碧昂丝在一个女子团体的试音会上遇见拉塔薇亚·罗伯森（lataviaroberson），两人与碧昂丝的好友凯莉·罗兰，以及其他团员共同组成一个表演rap和舞蹈的团体，团体原名为“girl'styme”，之后团员人数减到6名。 0.0046668393\n",
      "其他 其他语言中最常见的是中文（26.7%），其次为广东话（20.4）、希腊语（3.7%）以及阿拉伯语（3.6%）。 0.0049262564\n",
      "其他 经过这次战略挫折，腓特烈认识到，因为普鲁士本身人口有限，军中很多是德意志其他邦国的雇佣兵，这样的军队，必须要有铁的纪律才能凝聚成战斗力，而且绝不能分散使用。 0.0036221019\n",
      "其他 它可使usb设备，例如播放器或手机，从usb周边设备变为usb主机，与其他usb设备连接通信。 0.002967615\n",
      "其他 9月下旬，漫威选择赵婷执导这部电影，由于在会面中对赵留有良好印象，漫威担心她会选择其他大制片厂商的电影项目，双方很快签订了导演协议。 0.0044069467\n",
      "其他 dicom的档案是由标准化且自由型式的开头再加上一连串的影像数据，单一个dicom的物件只包含一张影像，但是此影像可能会有多个套图，这是为了能储存动态影像以及其他复图形式的资料，影像资料可以经压缩用在其他的格式上，包括了jpeg,jpeglossless,jpeg2000,lzwandrun-lengthencoding(rle)。 0.01151687\n",
      "其他 dicom的档案是由标准化且自由型式的开头再加上一连串的影像数据，单一个dicom的物件只包含一张影像，但是此影像可能会有多个套图，这是为了能储存动态影像以及其他复图形式的资料，影像资料可以经压缩用在其他的格式上，包括了jpeg,jpeglossless,jpeg2000,lzwandrun-lengthencoding(rle)。 0.0061049527\n",
      "其他 豹蛙会被不同的动物所猎食，如蛇、浣熊、其他青蛙及人类。 0.009612829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 2335856/2395389 [00:02<00:00, 840110.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "其他 2012年6月大选中奥尼尔再次当选议员，奥尼尔的与其他政党组成联合政府，在8月3日组成新一届政府，奥尼尔继续担任总理。 0.0031439252\n",
      "其他 pascal没有main或是其他相类似的关键字。 0.0051476783\n",
      "其他 eia-485上最常使用的协定都是属于，不过也有其他的通讯，例如（ssi）。 0.0073654703\n",
      "其他 猫剧的角色介绍，此剧的一大特色是舞台上的每只猫都有自己的名称和性格，这在其他的音乐剧并不常见。 0.010322793\n",
      "其他 《孙子兵法》注家杜牧认为，曹操将八十二篇孙子兵法删节为十三篇；但其他注家认为十三篇出自孙武本人，不是曹操删节的结果。 0.0077213612\n",
      "其他 在吴全病逝后，残存的移民也迁到其他地方去，城池也因而荒芜。 0.0035504568\n",
      "其他 1980年代，加拿大公园管理局将很多公园的设施私有化，如高尔夫球场等，并增加了使用其他设施的费用，以削减预算。 0.0069341515\n",
      "其他 同时，领英没有为中文用户提供某些重要功能，比如创建或加入群组，或是张贴长篇文章，而其他地方的用户就可以开展公开讨论、组建社区。 0.008136291\n",
      "其他 其后外尔向爱因斯坦等其他物理学家广泛讨论了这个理论在物理上的正确性，但最终这个理论被证明是在物理上不合理的。 0.0031362402\n",
      "其他 1979年5月10日，接掌新约教会的洪以利亚正式在锡安山定居，同工（牧师）反对他这样做，认为他这样是放下了新约教会的文字工作、以及其他地方教会；洪以利亚反驳指，是神要求他住在锡安山，有如摩西留在西奈山一样，离开锡安山就像离开神，此后同工的态度有所转变。 0.00602942\n",
      "其他 中建电讯更向法院申请禁制令，全面封杀刘德华为其他公司做唱片、接拍影视和广告等演出机会，等于全面封杀刘的演艺事业，结果禁制令成功，使得刘德华在禁制令生效期间估计损失收入上亿元。 0.0065243165\n",
      "其他 北部山区则主要依赖所经营的客运路线，其他包括和在辖内也都有经营客运路线。 0.005930889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2395389/2395389 [00:02<00:00, 985130.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "其他 不过这样它需要保护猎物，免受其他掠食者抢夺，但其保护策略就不得面知。 0.0067132274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tmp = ['其他']\n",
    "tmp =set(tmp)\n",
    "sent = ''\n",
    "for item in tqdm(saveres):\n",
    "    word = item[0]\n",
    "    i = item[1]\n",
    "    prob = item[2]\n",
    "    if item[0] in tmp:\n",
    "        print(word,''.join(infer_sents[i][:256]),prob)\n",
    "        sent = ''.join(infer_sents[i][:256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用户,0.599\n",
      "讨论,0.208\n",
      "地方,0.103\n",
      "公开讨论,0.035\n",
      "公开,0.035\n",
      "公,0.005\n",
      "论,0.003\n",
      "用,0.003\n",
      "方,0.002\n",
      "展公开,0.002\n",
      "展公开讨论,0.002\n",
      "开展公开讨论,0.002\n",
      "公开讨,0.002\n",
      "地,0.002\n",
      "展,0.001\n",
      "开展,0.001\n",
      "开展公开,0.001\n",
      "展公开讨,0.001\n",
      "开,0.001\n",
      "展公,0.001\n",
      "开展公开讨,0.000\n",
      "开展公,0.000\n",
      "讨论。,0.000\n",
      "户,0.000\n",
      "开讨,0.000\n",
      "开讨论,0.000\n",
      "公开讨论。,0.000\n",
      "讨,0.000\n",
      "开展公开讨论。,0.000\n",
      "其他地方的用户,0.000\n",
      "其他地方,0.000\n",
      "其他地方的用户可以开展公开讨论,0.000\n",
      "展公开讨论。,0.000\n",
      "用户可以开展公开讨论,0.000\n",
      "其他地方的用,0.000\n",
      "其他地方的,0.000\n",
      "其他地,0.000\n",
      "其他,0.000\n",
      "可以开展公开讨论,0.000\n",
      "用户可,0.000\n",
      "其他地方的用户可以开展,0.000\n",
      "地方的用户,0.000\n",
      "其他地方的用户可,0.000\n",
      "他地方,0.000\n",
      "其他地方的用户可以,0.000\n",
      "户可以开展公开讨论,0.000\n",
      "用户可以开展,0.000\n",
      "地方的用户可以开展公开讨论,0.000\n",
      "户可,0.000\n",
      "地方的,0.000\n",
      "可以开展,0.000\n",
      "其他地方的用户可以开,0.000\n",
      "其,0.000\n",
      "用户可以,0.000\n",
      "地方的用,0.000\n",
      "户可以开展,0.000\n",
      "用户可以开,0.000\n",
      "他地方的用户,0.000\n",
      "。,0.000\n",
      "地方的用户可以开展,0.000\n",
      "他地方的用户可以开展公开讨论,0.000\n",
      "可以开,0.000\n",
      "地方的用户可以,0.000\n",
      "的用户可以开展公开讨论,0.000\n",
      "可以,0.000\n",
      "可,0.000\n",
      "他地,0.000\n",
      "地方的用户可,0.000\n",
      "用户可以开展公开讨论。,0.000\n",
      "户可以,0.000\n",
      "户可以开,0.000\n",
      "开,0.000\n",
      "以开展公开讨论,0.000\n",
      "他地方的用,0.000\n",
      "他地方的,0.000\n",
      "以开展,0.000\n",
      "地方的用户可以开,0.000\n",
      "他,0.000\n",
      "的用户,0.000\n",
      "他地方的用户可以开展,0.000\n",
      "地方的用户可以开展公开讨论。,0.000\n",
      "的用户可以开展,0.000\n",
      "他地方的用户可以,0.000\n",
      "他地方的用户可,0.000\n",
      "方的用户可以开展公开讨论,0.000\n",
      "以开,0.000\n",
      "可以开展公开讨论。,0.000\n",
      "的用户可以,0.000\n",
      "户可以开展公开讨论。,0.000\n",
      "方的用户,0.000\n",
      "的用户可,0.000\n",
      "开讨论。,0.000\n",
      "他地方的用户可以开,0.000\n",
      "的用,0.000\n",
      "的用户可以开,0.000\n",
      "方的用户可以开展,0.000\n",
      "他地方的用户可以开展公开讨论。,0.000\n",
      "方的用,0.000\n",
      "方的,0.000\n",
      "其他地方的用户可以开展公开,0.000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sent='其他地方的用户可以开展公开讨论。'\n",
    "out = model.inference_one_sent(sent, top_k = 100, verbose=False,sm=True)\n",
    "for item in out:\n",
    "    ngram = ''.join(item[0][0])\n",
    "    prob = format(item[1],'.3f')\n",
    "    print(f'{ngram},{prob}')\n",
    "# out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p: 0.4152804182509506\n",
      "r: 0.628032345013477\n",
      "['24小时', '看起来', '革命军', '联邦铁路', '最适合', '菲尔德', '大天王', '交通线', '布劳恩', '同年8月', '留学生', '纳斯吉', '灯笼鱼', '县学生', '罗伊特', '管理员', '尼特拉', '开发商', '神学院', '电偶极', '威斯特', '台湾社', '布伦特', '德川家', '地杨梅', '混合制', '对台工作', '蓝绿色', '金像奖', '维伦纽夫', '爱达荷', '隔距兰', '内战爆发', '市议员', '分类法', '超级联赛', '最接近', '布哈拉', '西南太平洋', '下半年', '20岁', '伯纳德', '帝国皇帝', '比利亚', '佛得角', '奥利弗', '怎么做', '高尔夫', '布维尔', '电台节目', '集水区', '党领袖', '世纪末', '不定时', '美术家', '霍尔木兹', '见证人', '纽奥良', '纪念地', '塞缪尔', '研究社', '含氧量', '普通法', '有意识', '圣彼得', '中华民国陆', '海军少', '新文化', '人民委员', '澳门甲组', '郡太守', '卡鲁斯', '研究者', '艾森豪', '公安厅', '匈帝国', '三环路', '马克斯', '省人民政府', '卡德罗', '西印度', '皇太后', '西大区', '中央军', '扎波罗热', '锅炉房', '尼斯特', '教育学', '人民共和国', '研究系', '附加赛', '兰伯特', '凯瑟琳', '霍夫曼', '马拉维', '西班牙裔', '10次', '人口普查指定', '400米', '爱荷华', '大布尔卢克', '东南面', '吐鲁番', '第25届', '发行量', '卡尔斯鲁', '大虎山', '司令员', '生于上海', '明星赛', '托马斯', '坦尼斯', '训练场', '东上线', '中央书记处', '裁判所', '宁东站', '长老会', '中央情报', '主教堂', '乌拉尔', '自然地', '京都交通', '第十三届', '警察部队', '多目标', '普林斯', '葡萄园', '米尔纳', '第120师', '格鲁吉', '斯泰尔', '保护人', '伦比亚', '浪漫爱', '堪萨斯', '奥委会', '拉丁裔美国人', '国防军', '维尔县', '利维亚', '武备学堂', '区议会选举', '茄苳脚', '加来海峡', '大学法', '皮乌拉', '纳尔多', '低密度', '神射手', '吉尼亚', '写作人', '中文版', '布莱恩', '反战歌', '气管炎', '陨石坑', '省议员', '乙二醇', '宇宙微波背景', '共和国成立', '男主角', '发展局', '克劳利', '同年11月', '工艺品', '大学教授', '常委会', '可能性', '脊椎动物', '布兰登', '维吾尔', '美国加州', '过渡区', '体育节', '厚壳树', '信用社', '延伸至', '黄河南', '个旧市', '中华人民共和国政', '卡斯蒂利', '大皮萨里夫卡', '计算机系', '守望台圣经', '蒙塔尔', '奥克斯', '单位制', '土库曼', '海通道', '阿布维尔', '唱片制作', '海洋法', '大学校', '10分', '经济区', '俄罗斯苏维埃', '丘陵地', '北卡罗莱纳', '弗兰克']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2924923/1867590202.py:36: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  print(random.sample(diff_prec,200))\n"
     ]
    }
   ],
   "source": [
    "# occur_words = set(occur_words)\n",
    "re_patterns = [\n",
    "    r'^\\d+日$',\n",
    "    r'^\\d+月\\d*$',\n",
    "    r'^\\d+年$',\n",
    "    r'^\\d+年\\d+月$',\n",
    "    r'^\\d+年\\d+月\\d+日$',\n",
    "    r'^\\d+月\\d+日$',\n",
    "    r'^[公元]*\\d+世纪$',\n",
    "    r'^在\\d+年$',\n",
    "    r'^第\\d+$',\n",
    "    r'^\\d+年代$'\n",
    "    r'^月\\d+$'\n",
    "]\n",
    "import re\n",
    "def have_pat(term):\n",
    "    for pattern in re_patterns:\n",
    "        if re.search(pattern, term):\n",
    "            # print('yes')\n",
    "            return True\n",
    "    return False\n",
    "from collections import Counter\n",
    "occur_cnt = Counter(occur_words)\n",
    "new_key_terms = set([item for item in key_terms if item in occur_cnt and occur_cnt[item]>1 and len(item)>2])\n",
    "print('p:',len(new_key_terms.intersection(new_extracted))/len(new_extracted))\n",
    "print('r:',len(new_key_terms.intersection(new_extracted))/len(new_key_terms))\n",
    "# 找汉字\n",
    "import re\n",
    "hanzire = re.compile(u'[\\u4e00-\\u9fa5]')\n",
    "# hanzire.search(target)\n",
    "noyear = set([item for item in new_key_terms if  hanzire.search(item) and not have_pat(item)])\n",
    "diff_prec = noyear.difference(new_extracted)\n",
    "diff_prec\n",
    "# print(diff_prec)\n",
    "import random\n",
    "print(random.sample(diff_prec,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['为害新娘', '石油公司', '签名人', '防炮车', '通讯及监察', '可证明', '街市街市', '国家铁路建设', '枚方町', '销量排行榜', '电视事业', '林柄存', '粉壁岭', '罗马帝国统治', '禾鸭生态', '美国世嘉', '中共中央总书记', '卵二姐', '鱼快乐', '医介辅', '货运营业', '职业技术学院', '钢铁人', '最高人民法院', '后鳃类物种', '军官级', '全体会议', '硕士研究生教育', '国务院副总理', '葛雷佛', '相似度', '埃尔斯特', '人权研究所', '浪淘沙三部曲', '中国双节棍邀请赛', '中央草坪', '赛车手', '广播电视', '主要车站', '歌唱大赛', '勇者斗恶龙', '推力重量', '美国nba', '亚伯拉罕·伊本', '西文化', '舰艇学院', '临时货币', '换乘通道', '儒林戏', '李家窑', '巴士车厂', '主管部门', '蒸汽机车制造厂', '特种部队2', '《圣诞祭》', '秘书室', '缓冲簧', '全自动波箱', '田吉兹', '林克斯市场', '生活环境', '52赫兹', '背景乐', '票选结果', '照明灯', '社会经济', '标准反应焓', '谱分辨率', '南方都市报', '喝茶会', '严重冲突', '文学教授', '圣经书社', '冶金集团', '热带高压脊', 'nba联盟', '荣誉称号', '少年时期', '艾芙琳', '饱和直链脂肪酸', '詹姆斯、丹尼', '新填地街市场', '亚冠小组赛', '雅砻江口', '通讯委员会', '制作动画', '丹尼、汤姆', '常规时间', '原乡人', '“慰安妇”', '攻克北京', '二重唱公演', '郑和舰队', '政治局常委', '《信报》', '萨默赛特', '阿纳斯塔', '人权研究', '女主角奖', '人民检察院', '第三方软件', '绩优教职员工', '数字转换器', '中华成棒', '美国政府', '魔法史', '绝对领域', '客运中心', '马利克·艾亚兹', '填地街市场', 'ldl胆固醇', '香港电影金像奖', '吸虫囊蚴', '荷兰当局', '合约无效', '何文田北', '暹罗王位', '社会经济问题', '剑击队', '民族主义者', '绿色颜料', '特大休闲集团', '青年合唱', '152毫米', '特殊监管', '生活管理', '玛丽·泰勒', '叱咤乐坛', '世纪帝国', '少女漫画', '玛丹娜', '个性婚纱摄影', '统一说', '纯涡轮喷射', '不动产管理机构', '女子文理学院', '太刀洗', '彩绘玻璃', '一分钟持续风速', '可疑交易', '重唱公演', '上海古北', '诸葛四郎', '班尼特', '坦克集团军', '“中国”', '咿咿呀呀', '林美香', '私营企业', '第1坦克集团军', '经济问题', '工业总产值', '管理中心', '懋隆艺术', '沿海地区', '11米', '海峡两岸', '克苏鲁', '写作人员', '博丹茨基', '服制规则', '武器系统', '问题1', '王母弟甥舅', '日本冲绳', '世界资讯', '游行活动', '截取通讯', '中联航', '太子右卫', '加礼宛人', '航管员', '北平社会调查', '固定重联版', '廉租屋住宅', '中国国民党中央', '半日制', '“被遗忘的军队”', '新填地街市', '20世纪中期', '中央人民政府', '吉尼斯世界', '该省西部', '淳祐乙巳', '“芋虫”', '亚洲外援', '皇家文学', '戏剧学系', '委员会主席', '票房收入', '国家和地区', '安如香', '世界巡回', '《台湾日报》', '精灵宝可梦', 'x射线天文', '雷的灵魂', '韩国kbs', '索拉博', '平均气温']\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation as punc\n",
    "from zhon.hanzi import punctuation as zh_punc\n",
    "punc = set(punc+zh_punc)\n",
    "def have_punc(s,punc = punc):\n",
    "    for c in s:\n",
    "        if c in punc:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "diff_rec  = set(new_extracted).difference(noyear)\n",
    "# twot = set(two_terms)\n",
    "diff_rec = [item for item in diff_rec if hanzire.search(item) and not have_pat(item) and len(item)>2]\n",
    "# diff_rec\n",
    "print(random.sample(diff_rec,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "diff_prec = [item for item in diff_prec if '第' not in item]\n",
    "print(random.sample(diff_prec,len(diff_prec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_terms = []\n",
    "with open('/home/wangzhitong/data2/all_train_terms.txt','r') as f:\n",
    "    for line in f:\n",
    "        all_terms.append(line.strip())\n",
    "all_terms = set(all_terms)\n",
    "allnoyear = set([item for item in all_terms if item in occur_words and '年' not in item and '世纪' not in item and hanzire.search(item) and not have_punc(item)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_terms = []\n",
    "with open('/home/wangzhitong/data2/all_train_terms.txt','r') as f:\n",
    "    for line in tqdm(f):\n",
    "        word = line.strip()\n",
    "        if len(word )==2:\n",
    "            two_terms.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_rec = set(new_extracted).difference(allnoyear)\n",
    "# print(diff_rec)\n",
    "print(random.sample(diff_rec,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 29.8\n",
    "r = 95.1\n",
    "f1 = 2*p*r/(p+r)\n",
    "print(f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  5 2022, 06:56:58) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e2f12ee792ee2aa305b6d1098f116bd99921cc7cffadcaa025bbef97522db743"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
